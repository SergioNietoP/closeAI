{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_key = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion_and_token_count(messages, \n",
    "                                 model=\"gpt-3.5-turbo\", \n",
    "                                 temperature=0.0, max_tokens=5000):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature, \n",
    "        max_tokens=max_tokens, \n",
    "    )\n",
    "\n",
    "    content = response.choices[0].message[\"content\"]\n",
    "\n",
    "\n",
    "    token_dict = {\n",
    "        'prompt_tokens': response['usage']['prompt_tokens'],\n",
    "        'completion_tokens': response['usage']['completion_tokens'],\n",
    "        'total_tokens': response['usage']['total_tokens'],\n",
    "    }\n",
    "\n",
    "    return content, token_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape (203576401.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[12], line 4\u001b[1;36m\u001b[0m\n\u001b[1;33m    file_path = 'C:\\Users\\Sergio\\Desktop\\TWS\\tws-workspace\\closeAI\\Examples\\content_generation\\content\\Manual-nutricion-dietetica-CARBAJAL.pdf'\u001b[0m\n\u001b[1;37m                                                                                                                                               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import PyPDF2\n",
    "\n",
    "file_path = (r'C:/Users/Sergio/Desktop/tws-workspace/closeAI/Examples/content_generation/content/Manual-nutricion-dietetica-CARBAJAL.pdf')\n",
    "\n",
    "def clean_pdf_text(file_path):\n",
    "    # Open the PDF file in read-binary mode\n",
    "    with open(file_path, \"rb\") as file:\n",
    "        # Initialize a PDF file reader object\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "\n",
    "        # Initialize an empty string to hold the extracted text\n",
    "        text = \"\"\n",
    "\n",
    "        # Loop over all the pages in the PDF (assuming the PDF text is to be read page by page)\n",
    "        for page_number in range(len(reader.pages)):\n",
    "            # Extract the text from the current page\n",
    "            page_text = reader.pages[page_number].extract_text()\n",
    "            \n",
    "            # Add the page text to the main text string\n",
    "            text += \"\\n\" + page_text\n",
    "\n",
    "    # Define patterns for lines to be removed\n",
    "    patterns = [\n",
    "        r'https?://[^\\s<>\"]+|www\\.[^\\s<>\"]+',  # URLs\n",
    "        r'\\bEnero\\b|\\bFebrero\\b|\\bMarzo\\b|\\bAbril\\b|\\bMayo\\b|\\bJunio\\b|\\bJulio\\b|\\bAgosto\\b|\\bSeptiembre\\b|\\bOctubre\\b|\\bNoviembre\\b|\\bDiciembre\\b',  # Months in Spanish\n",
    "        r'\\bÍndice\\b',  # Index\n",
    "        r'^\\d+\\.$',  # Lines that start with a number and end with a dot, which are likely index entries\n",
    "        r'^\\s*\\uf0b7',  # Lines that start with a bullet point (·), which are likely sub-index entries\n",
    "         r'\\b\\b',  # Lines that start with a (o), which are likely sub-index entries\n",
    "        r'^\\d+$',  # Lines that contain only a number, which are likely page numbers\n",
    "        r'\\.{2,}',  # Two or more dots in a row, which are likely from index entries\n",
    "        r'\\s*[\\.0-9]+\\s*$'  # Trailing dots and numbers\n",
    "    ]\n",
    "\n",
    "    # Split the text into lines\n",
    "    lines = text.split('\\n')\n",
    "\n",
    "    # Remove duplicate lines\n",
    "    lines = list(dict.fromkeys(lines))\n",
    "\n",
    "    # Initialize a list to hold cleaned lines\n",
    "    cleaned_lines = []\n",
    "\n",
    "    for line in lines:\n",
    "        # If the line matches any of the patterns, skip it\n",
    "        if any(re.search(pattern, line) for pattern in patterns):\n",
    "            continue\n",
    "\n",
    "        # If the line is empty, skip it\n",
    "        if line.strip() == \"\":\n",
    "            continue\n",
    "\n",
    "        # If we reach here, the line is clean, so add it to the list\n",
    "        cleaned_lines.append(line.strip())\n",
    "\n",
    "    # Join the cleaned lines back into a single string\n",
    "    cleaned_text = \"\\n\".join(cleaned_lines)\n",
    "\n",
    "    # Replace ellipsis (…) with a single space\n",
    "    cleaned_text = re.sub(r'\\…', ' ', cleaned_text)\n",
    "\n",
    "    return cleaned_text\n",
    "\n",
    "print(clean_pdf_text(file_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delimiter = \"####\"\n",
    "system_message = f\"\"\"\n",
    "You are an exceptional topics test generator. I am going to provide you with assessable titles. Follow these steps to answer.\n",
    "\n",
    "Step 0:#### Basic parameters for future steps:\n",
    "Language: Spanish\n",
    "\n",
    "Step 1:#### Conduct in-depth research on each assessable title. This should include the definition, key concepts, and primary subjects \\\n",
    "as if they were a comprehensive university course. Do not output any information in this stage; it will be used in the following steps.\n",
    "\n",
    "Step 2: #### Read all the info  from the pdfs provided and prioritise the information in it and use in a complemmentary way the information you have in your knowledge. You will see that in the info extracted from the pdf there are a lot of characters that are not letters, delete that information.\n",
    "\n",
    "Step 3:#### Based on your research, develop broad, overarching 10 short topics for each assessable title. It´s better if topics try to evaluate general and basic concepts of the assessable.\\\n",
    "Each topic should cover a large portion of the assessable's material and allow for a holistic evaluation of a candidate's understanding. Take into consideration Step 0. Develop 10 topics for each assessable title. \\\n",
    "The topics develop should be theoretical and advance basic concepts.\n",
    "When choosing the 10 topics, bear in mind the following scoring criteria, show me each score, each rated out of 100 and showing the scores:\n",
    "\n",
    "Relevance: The topic should be directly related to the title and description of the assessable. \n",
    "\n",
    "General: The topic should be general and not an speciality, general concepts and advance basic notions. This one is the most important metric, \\\n",
    "generate topics that are very general and broad in the subject and do not focus in a specific syllabus.\n",
    "\n",
    "Breadth: The topic should be broad enough to encompass a wide range of subtopics within the assessable. \n",
    "\n",
    "Clarity: The topic should be clear and understandable.\n",
    "\n",
    "Evaluative Effectiveness: The topic's capability to serve as a robust assessment tool for a professional's comprehension of the general concepts within the title.\n",
    "\n",
    "Step 3:#### Review the words in the topics and in case the name of the assessable title appears at the begginingof the topic, rewrite the topic like this: \\\n",
    "For example, title: Nutricion; topic: Nutricion and calidad alimentaria; Result: Calidad alimentaria en nutricion\n",
    "\n",
    "Step 4:#### Rank the topics in descending order, based on their average score across all five scoring criteria. List these topics along with their scores.\n",
    "\n",
    "Step 5.1:#### Finally, select the top 5 topics that collectively cover the majority of the assessable's content and will allow for a comprehensive and correct evaluation \\\n",
    "of a candidate's knowledge. These collective topics chosen should be broad, covering multiple key areas within the assessable. They shouldnt be an speciality inside of the title, \\\n",
    "they must be general and broad topics of the title any professional will know. Topics chosen must not be similar, so the chosen as a group will cover the mayority of the assessable syllabus.\n",
    "\n",
    "Step 5.2: #### Develop groups, the groups selected must collectively cover the majority of the assessable's syllabus and will allow for a comprehensive and correct evaluation \\\n",
    "of a candidate's knowledge. These groups must not have similar topics so we can make a correct and complete evaluation of the candidate´s knowledge in the assessable syllabus. \\\n",
    "For each title, develop 2 groups that contain 5 titles each.\n",
    "\n",
    "Use the following format:\n",
    "Step 1:#### <step 1 reasoning>\n",
    "Step 2:#### <step 2 reasoning>\n",
    "Step 3:#### <step 3 reasoning>\n",
    "Step 4:#### <step 4 reasoning>\n",
    "Step 5.1:#### <final result 1>\n",
    "Step 5.2:#### <final result 2>\n",
    "\n",
    "\n",
    "Make sure to include {delimiter} to separate every step. All the information of your development and the result has to be in Spanish.\n",
    "\n",
    "The assessable title is Nutricion\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (2242258484.py, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[37], line 6\u001b[1;36m\u001b[0m\n\u001b[1;33m    {'role': 'assistant',\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "user_message = \" [{'title': 'Enfermería', 'title':'Nutrición'}] \"\n",
    "\n",
    "messages =  [  \n",
    "{'role':'system', \n",
    " 'content': system_message},  \n",
    " {'role': 'assistant',\n",
    "  'content': text}  \n",
    "{'role':'user', \n",
    " 'content': f\"{delimiter}{user_message}{delimiter}\"},  \n",
    "] \n",
    "\n",
    "# response, token_dict = get_completion_and_token_count(messages)\n",
    "# print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
